# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SYC178f3IWHFlqENcIIHH7hzCYIY1opU
"""

!pip install skl2onnx


# Required Libraries
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, AdaBoostClassifier, AdaBoostRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, mean_absolute_error
from imblearn.over_sampling import SMOTE
from skl2onnx import convert_sklearn
from skl2onnx.common.data_types import FloatTensorType
import pandas as pd
import numpy as np
from collections import Counter

# Define the base name
base_name = "현대차"

# Load Dataset
data = pd.read_csv('/content/현대차.csv')  # Replace with your dataset path

# Preprocess Data
numeric_columns = ['종가', '대비', '고가', '저가', 'EPS', 'PER',
                   '외국인 보유수량', '기관 합계', '기타법인', '개인', '외국인 합계']
for col in numeric_columns:
    data[col] = data[col].astype(str).replace('-', None).str.replace(',', '').astype(float)

# Define target variable for classification
def classify_change(value):
    if value > 0:
        return 1
    elif value < 0:
        return -1
    else:
        return 0

data['대비_class'] = data['대비'].apply(classify_change)
y_class = data['대비_class']  # Classification target
y_reg = data['대비']          # Regression target

# Define features
features = ['종가', '고가', '저가', 'EPS', 'PER',
            '외국인 보유수량', '기관 합계', '기타법인', '개인', '외국인 합계']
X = data[features]

# Handle missing values
X = X.fillna(X.mean())
X = X.replace([np.inf, -np.inf], np.nan).fillna(0)

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Address class imbalance using SMOTE for classification
rare_class_threshold = 2
# Correct filtering logic for filtered_indices
filtered_indices = y_class.map(Counter(y_class)) >= rare_class_threshold

# Filter data consistently
X_filtered = X_scaled[filtered_indices]
y_class_filtered = y_class[filtered_indices]
y_reg_filtered = y_reg[filtered_indices].reset_index(drop=True)

# Debug lengths to ensure alignment
print("Length of X_filtered:", len(X_filtered))
print("Length of y_class_filtered:", len(y_class_filtered))
print("Length of y_reg_filtered:", len(y_reg_filtered))

# Validate lengths
if len(X_filtered) != len(y_class_filtered) or len(y_class_filtered) != len(y_reg_filtered):
    raise ValueError("Mismatch in lengths after filtering!")


# Adjust k_neighbors dynamically
class_counts = Counter(y_class_filtered)
min_class_count = min(class_counts.values())
k_neighbors = min(5, min_class_count - 1) if min_class_count > 1 else 1

# Apply SMOTE for classification
smote = SMOTE(random_state=42, k_neighbors=k_neighbors)
X_resampled, y_class_resampled = smote.fit_resample(X_filtered, y_class_filtered)

# Align y_reg_resampled with SMOTE
smote_indices = smote.fit_resample(
    np.arange(len(y_reg_filtered)).reshape(-1, 1), y_class_filtered
)[0].flatten()

if len(smote_indices) != len(y_class_resampled):
    raise ValueError("Inconsistent lengths after resampling!")

y_reg_resampled = np.array([y_reg_filtered.iloc[i] for i in smote_indices])
y_reg_resampled = pd.Series(y_reg_resampled).reset_index(drop=True)

# Split datasets
X_train, X_test, y_class_train, y_class_test = train_test_split(
    X_resampled, y_class_resampled, test_size=0.2, random_state=42, stratify=y_class_resampled
)
_, _, y_reg_train, y_reg_test = train_test_split(
    X_resampled, y_reg_resampled, test_size=0.2, random_state=42, stratify=y_class_resampled
)

# Train Random Forest for classification
rf_class_model = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42)
rf_class_model.fit(X_train, y_class_train)

# Train Random Forest for regression
rf_reg_model = RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42)
rf_reg_model.fit(X_train, y_reg_train)

# Train AdaBoost for classification
ab_class_model = AdaBoostClassifier(n_estimators=50, random_state=42)
ab_class_model.fit(X_train, y_class_train)

# Train AdaBoost for regression
ab_reg_model = AdaBoostRegressor(n_estimators=50, random_state=42)
ab_reg_model.fit(X_train, y_reg_train)

# Validate Models
print("Validation Results:")
print("\nRandom Forest Classification Report:")
print(classification_report(y_class_test, rf_class_model.predict(X_test)))
print("\nRandom Forest Regression MAE:")
print(mean_absolute_error(y_reg_test, rf_reg_model.predict(X_test)))
print("\nAdaBoost Classification Report:")
print(classification_report(y_class_test, ab_class_model.predict(X_test)))
print("\nAdaBoost Regression MAE:")
print(mean_absolute_error(y_reg_test, ab_reg_model.predict(X_test)))

# Convert and save Random Forest classification model to ONNX
rf_class_onnx = convert_sklearn(
    rf_class_model,
    initial_types=[('float_input', FloatTensorType([None, len(features)]))],
    target_opset=12
)
rf_class_onnx_name = f"{base_name}_rf_class.onnx"
with open(rf_class_onnx_name, "wb") as f:
    f.write(rf_class_onnx.SerializeToString())
print(f"Random Forest Classification ONNX model saved as '{rf_class_onnx_name}'.")

# Convert and save Random Forest regression model to ONNX
rf_reg_onnx = convert_sklearn(
    rf_reg_model,
    initial_types=[('float_input', FloatTensorType([None, len(features)]))],
    target_opset=12
)
rf_reg_onnx_name = f"{base_name}_rf_reg.onnx"
with open(rf_reg_onnx_name, "wb") as f:
    f.write(rf_reg_onnx.SerializeToString())
print(f"Random Forest Regression ONNX model saved as '{rf_reg_onnx_name}'.")

# Convert and save AdaBoost classification model to ONNX
ab_class_onnx = convert_sklearn(
    ab_class_model,
    initial_types=[('float_input', FloatTensorType([None, len(features)]))],
    target_opset=12
)
ab_class_onnx_name = f"{base_name}_ab_class.onnx"
with open(ab_class_onnx_name, "wb") as f:
    f.write(ab_class_onnx.SerializeToString())
print(f"AdaBoost Classification ONNX model saved as '{ab_class_onnx_name}'.")

# Convert and save AdaBoost regression model to ONNX
ab_reg_onnx = convert_sklearn(
    ab_reg_model,
    initial_types=[('float_input', FloatTensorType([None, len(features)]))],
    target_opset=12
)
ab_reg_onnx_name = f"{base_name}_ab_reg.onnx"
with open(ab_reg_onnx_name, "wb") as f:
    f.write(ab_reg_onnx.SerializeToString())
print(f"AdaBoost Regression ONNX model saved as '{ab_reg_onnx_name}'.")

